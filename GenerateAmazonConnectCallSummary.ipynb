{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0e49320-a08f-4817-b01b-c7f39d786480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7d551e4-81f7-4f9c-bf45-f1be42fd4652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.Lambda_Helper import Lambda_Helper\n",
    "from helpers.S3_Helper import S3_Helper\n",
    "from helpers.Display_Helper import Display_Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71ef0fdf-daea-4a58-aab4-139a145b8fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_helper = Lambda_Helper()\n",
    "# deploy_function\n",
    "# add_lambda_trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6ad0620-9347-4384-83e0-aabfc36123fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_helper = S3_Helper()\n",
    "# upload_file\n",
    "# download_object \n",
    "# list_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0563e059-cb3d-471e-bb16-5527945c84ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_helper = Display_Helper()\n",
    "# text_file\n",
    "# json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ed815dd-9eec-465a-b12e-d3ef66b3d90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LEARNERS3BUCKETNAMETEXT'] = '[YOURBUCKET]'\n",
    "os.environ['LAMBDALAYERVERSIONARN'] = '[YOURARN]'\n",
    "os.environ['LEARNERS3BUCKETNAMEAUDIO'] = '[YOURBUCKET]'\n",
    "bucket_name_text = os.environ['LEARNERS3BUCKETNAMETEXT']\n",
    "bucket_name_audio = os.environ['LEARNERS3BUCKETNAMEAUDIO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24d2d26f-5404-4d70-899a-00c74f8971c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting prompt_template.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile prompt_template.txt\n",
    "I need to summarize a conversation. The transcript of the conversation is between the <data> XML like tags.\n",
    "The conversation is in French, please translate it.\n",
    "<data>\n",
    "{{transcript}}\n",
    "</data>\n",
    "\n",
    "The summary must contain a one word sentiment analysis,\n",
    "and a list of issues, problems or causes of friction during the conversation,\n",
    "and a short resume of the call.\n",
    "\n",
    "The output must be provided in JSON format shown in the following example.\n",
    "\n",
    "Example output:\n",
    "{\n",
    "    \"version\": 0.1,\n",
    "    \"sentiment\": <sentiment>,\n",
    "    \"issues\": [\n",
    "        {\n",
    "            \"topic\": <topic>,\n",
    "            \"summary\": <issue_summary>,\n",
    "        }\n",
    "    ],\n",
    "     \"resume\": <resume>\n",
    "}\n",
    "\n",
    "An `issue_summary` must only be one of:\n",
    "{%- for topic in topics %}\n",
    " - `{{topic}}`\n",
    "{% endfor %}\n",
    "\n",
    "Write the JSON output in French and nothing more.\n",
    "\n",
    "Here is the JSON output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f43084d0-e277-4373-bd73-e1271c164b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_helper.text_file('prompt_template.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a82913-1eb1-48e4-978d-e2f2a3d1de55",
   "metadata": {},
   "source": [
    "### Create the Lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f275b88a-5502-4da4-939b-b1d2eb50918d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lambda_function_summarisation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lambda_function_summarisation.py\n",
    "\n",
    "\n",
    "#############################################################\n",
    "#\n",
    "# This Lambda function is written to a file by the notebook \n",
    "# It does not run in the notebook!\n",
    "#\n",
    "#############################################################\n",
    "\n",
    "import boto3\n",
    "import json \n",
    "from jinja2 import Template\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "bedrock_runtime = boto3.client('bedrock-runtime', 'us-east-1')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \n",
    "    bucket = event['Records'][0]['s3']['bucket']['name']\n",
    "    key = event['Records'][0]['s3']['object']['key']\n",
    "    \n",
    "    # One of a few different checks to ensure we don't end up in a recursive loop.\n",
    "    if \"-transcript.json\" not in key: \n",
    "        print(\"This demo only works with *-transcript.json.\")\n",
    "        return\n",
    "    \n",
    "    try: \n",
    "        file_content = \"\"\n",
    "        \n",
    "        response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "        \n",
    "        file_content = response['Body'].read().decode('utf-8')\n",
    "        \n",
    "        transcript = extract_transcript_from_textract(file_content)\n",
    "\n",
    "        print(f\"Successfully read file {key} from bucket {bucket}.\")\n",
    "\n",
    "        print(f\"Transcript: {transcript}\")\n",
    "        \n",
    "        summary = bedrock_summarisation(transcript)\n",
    "        \n",
    "        s3_client.put_object(\n",
    "            Bucket=bucket,\n",
    "            Key='results.txt',\n",
    "            Body=summary,\n",
    "            ContentType='text/plain'\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps(f\"Error occurred: {e}\")\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps(f\"Successfully summarized {key} from bucket {bucket}. Summary: {summary}\")\n",
    "    }\n",
    "        \n",
    "        \n",
    "        \n",
    "def extract_transcript_from_textract(file_content):\n",
    "\n",
    "    transcript_json = json.loads(file_content)\n",
    "\n",
    "    output_text = \"\"\n",
    "    current_speaker = None\n",
    "\n",
    "    items = transcript_json['results']['items']\n",
    "\n",
    "    # Iterate through the content word by word:\n",
    "    for item in items:\n",
    "        speaker_label = item.get('speaker_label', None)\n",
    "        content = item['alternatives'][0]['content']\n",
    "        \n",
    "        # Start the line with the speaker label:\n",
    "        if speaker_label is not None and speaker_label != current_speaker:\n",
    "            current_speaker = speaker_label\n",
    "            output_text += f\"\\n{current_speaker}: \"\n",
    "        \n",
    "        # Add the speech content:\n",
    "        if item['type'] == 'punctuation':\n",
    "            output_text = output_text.rstrip()  # Remove the last space\n",
    "        \n",
    "        output_text += f\"{content} \"\n",
    "        \n",
    "    return output_text\n",
    "        \n",
    "\n",
    "def bedrock_summarisation(transcript):\n",
    "    \n",
    "    with open('prompt_template.txt', \"r\") as file:\n",
    "        template_string = file.read()\n",
    "\n",
    "    data = {\n",
    "        'transcript': transcript,\n",
    "        'topics': ['charges', 'location', 'availability']\n",
    "    }\n",
    "    \n",
    "    template = Template(template_string)\n",
    "    prompt = template.render(data)\n",
    "    \n",
    "    print(prompt)\n",
    "    # Invoke Claude 3 with the text prompt\n",
    "    model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    \n",
    "    try:\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=model_id,\n",
    "            body=json.dumps(\n",
    "                {\n",
    "                    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "                    \"max_tokens\": 1024,\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [{\"type\": \"text\", \"text\": prompt}],\n",
    "                        }\n",
    "                    ],\n",
    "                }\n",
    "            ),\n",
    "        )\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps(f\"Error occurred: {e}\")\n",
    "        }\n",
    "\n",
    "    result = json.loads(response.get(\"body\").read())\n",
    "    output_list = result.get(\"content\", [])\n",
    "    text = output_list[0][\"text\"]\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca90bac8-ac6b-46c1-9e43-df66381f6095",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lambda_function_transcript.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lambda_function_transcript.py\n",
    "\n",
    "#############################################################\n",
    "#\n",
    "# This Lambda function is written to a file by the notebook \n",
    "# It does not run in the notebook!\n",
    "#\n",
    "#############################################################\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "transcribe_client = boto3.client('transcribe', region_name='us-east-1')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    # Extract the bucket name and key from the incoming event\n",
    "    bucket = event['Records'][0]['s3']['bucket']['name']\n",
    "    key = event['Records'][0]['s3']['object']['key']\n",
    "\n",
    "    # One of a few different checks to ensure we don't end up in a recursive loop.\n",
    "    if key != \"dialog.wav\": \n",
    "        print(\"This demo only works with dialog.wav.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        \n",
    "        job_name = 'transcription-job-' + str(uuid.uuid4()) # Needs to be a unique name\n",
    "\n",
    "        response = transcribe_client.start_transcription_job(\n",
    "            TranscriptionJobName=job_name,\n",
    "            Media={'MediaFileUri': f's3://{bucket}/{key}'},\n",
    "            MediaFormat='wav',\n",
    "            LanguageCode='en-US',\n",
    "            OutputBucketName= os.environ['S3BUCKETNAMETEXT'],  # specify the output bucket\n",
    "            OutputKey=f'{job_name}-transcript.json',\n",
    "            Settings={\n",
    "                'ShowSpeakerLabels': True,\n",
    "                'MaxSpeakerLabels': 2\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps(f\"Error occurred: {e}\")\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps(f\"Submitted transcription job for {key} from bucket {bucket}.\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d5db00a-6e54-4723-858f-ffa15ec49a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping function...\n",
      "Looking for existing function...\n",
      "Function LambdaFunctionSummarize exists. Updating code...\n",
      "Function LambdaFunctionSummarize code updated: 2024-04-09T15:48:08.000+0000\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "lambda_helper.deploy_function(\n",
    "    [\"lambda_function_summarisation.py\", \"prompt_template.txt\"],\n",
    "    function_name=\"LambdaFunctionSummarize\", module_name=\"lambda_function_summarisation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "338b623c-d8f4-4da4-8f58-0e93e903c57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using function name of deployed function: LambdaFunctionSummarize\n",
      "Removed existing permission: s3-trigger-permission\n",
      "Permission added with Statement: {\n",
      "    \"Sid\": \"s3-trigger-permission\",\n",
      "    \"Effect\": \"Allow\",\n",
      "    \"Principal\": {\n",
      "        \"Service\": \"s3.amazonaws.com\"\n",
      "    },\n",
      "    \"Action\": \"lambda:InvokeFunction\",\n",
      "    \"Resource\": \"arn:aws:lambda:us-east-1:284474675936:function:LambdaFunctionSummarize\",\n",
      "    \"Condition\": {\n",
      "        \"ArnLike\": {\n",
      "            \"AWS:SourceArn\": \"arn:aws:s3:::aaagius-6723reufiwdsyv\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Trigger added for aaagius-6723reufiwdsyv -> LambdaFunctionSummarize\n"
     ]
    }
   ],
   "source": [
    "lambda_helper.filter_rules_suffix = \"json\"\n",
    "lambda_helper.add_lambda_trigger(bucket_name_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81a1f1e-2a05-4813-b9c5-ed653af19a8d",
   "metadata": {},
   "source": [
    "### Deploy your lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d532b0f-9d02-439c-bd2c-89fbdf0092e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping function...\n",
      "Looking for existing function...\n",
      "Function LambdaFunctionTranscribe does not exist. Creating...\n",
      "Function LambdaFunctionTranscribe created: arn:aws:lambda:us-east-1:284474675936:function:LambdaFunctionTranscribe\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "lambda_helper.lambda_environ_variables = {'S3BUCKETNAMETEXT' : bucket_name_text}\n",
    "lambda_helper.deploy_function([\"lambda_function_transcript.py\"], function_name=\"LambdaFunctionTranscribe\", module_name=\"lambda_function_transcript\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5810a5bf-ce60-4877-82f7-35d0e5a27196",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permission added with Statement: {\n",
      "    \"Sid\": \"s3-trigger-permission\",\n",
      "    \"Effect\": \"Allow\",\n",
      "    \"Principal\": {\n",
      "        \"Service\": \"s3.amazonaws.com\"\n",
      "    },\n",
      "    \"Action\": \"lambda:InvokeFunction\",\n",
      "    \"Resource\": \"arn:aws:lambda:us-east-1:284474675936:function:LambdaFunctionTranscribe\",\n",
      "    \"Condition\": {\n",
      "        \"ArnLike\": {\n",
      "            \"AWS:SourceArn\": \"arn:aws:s3:::aaagius-audio-6723reufiwdsyv\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Trigger added for aaagius-audio-6723reufiwdsyv -> LambdaFunctionTranscribe\n"
     ]
    }
   ],
   "source": [
    "lambda_helper.filter_rules_suffix = \"wav\"\n",
    "lambda_helper.add_lambda_trigger(bucket_name_audio, function_name=\"LambdaFunctionTranscribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa76d1c9-879e-44f4-bcf3-f3512a99bb0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object 'dialog.wav' uploaded to bucket 'aaagius-audio-6723reufiwdsyv'\n"
     ]
    }
   ],
   "source": [
    "s3_helper.upload_file(bucket_name_audio, 'dialog.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62cabe91-7bb3-4b2a-9803-6ee8c4ccf92e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object: dialog.wav, Created on: 2024-04-09 15:48:27+00:00\n"
     ]
    }
   ],
   "source": [
    "s3_helper.list_objects(bucket_name_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4b4d9e5-7e0c-4ac2-ba27-d6327fd65929",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No objects found in the bucket: aaagius-6723reufiwdsyv\n"
     ]
    }
   ],
   "source": [
    "s3_helper.list_objects(bucket_name_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7bf1688d-7e12-4716-87b6-84d012316119",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object 'results.txt' from bucket 'aaagius-6723reufiwdsyv' to './results.txt'\n"
     ]
    }
   ],
   "source": [
    "s3_helper.download_object(bucket_name_text, 'results.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a952728-526a-4f02-921c-01576d1aae3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results.txt:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='width: 600px; word-wrap: break-word;'><pre>{<br>    &quot;version&quot;: 0.1,<br>    &quot;sentiment&quot;: &quot;neutre&quot;,<br>    &quot;issues&quot;: [],<br>    &quot;resume&quot;: &quot;Il s&#x27;agit d&#x27;une brève conversation de salutation sans aucun problème ou sujet particulier abordé.&quot;<br>}</pre></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_helper.text_file('results.txt')"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
